{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基本概念\n",
    "- 对大量未知标注的数据集，按照数据内部存在的数据特征，划分为多个不同的类别，使类别内的数据比较相似，类别之间的数据相似度较小；\n",
    "- 重点是计算样本之间的相似度，有时候也成为样本的距离\n",
    "- 聚类算法是无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 样本间的相似度的度量\n",
    "1. 距离计算公式1\n",
    "   - 闵可夫斯基距离特殊化：dist(X, Y) = \n",
    "   - p 为1时，曼哈顿距离（城市距离）\n",
    "   - p 为2时，欧式距离\n",
    "   - p 趋近于无穷大时，切比雪夫距离\n",
    "2. 距离计算公式2\n",
    "   - 夹角余弦相似度\n",
    "   - KL距离（相对熵）\n",
    "3. 距离计算3\n",
    "   - 杰卡德相似系数\n",
    "   - 皮尔逊相关系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 聚类的思想\n",
    "1. 给定一个包含m个对象的数据集，构建一个具有k个簇的模型，满足以下条件：\n",
    "   - 每个簇中至少包含一个对象\n",
    "   - 每个对象属于且仅属于一个簇\n",
    "   - 将满足上述条件的k个簇成为一个合理的聚类划分\n",
    "2. 划分聚类的基本思想\n",
    "   - 对于给定的类别数目k，首先给定初始划分，通过迭代改变样本的隶属关系，使得每次处理后得到的划分方式比上一次好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means算法\n",
    "1. 假设某个样本T = X1,X2,……,Xn；则算法步骤为（欧式距离）：\n",
    "   - 随机选择初始的k个簇的中心a1,a2,···,aj\n",
    "   - 对于每个样本Xi,计算距离，得到距离簇中心aj最近的簇j;\n",
    "   - 使用上一步划分每个簇所有样本的均值，作为簇的中心点aj；\n",
    "   - 重复上述两步，直到某个终止条件\n",
    "2. 终止条件：\n",
    "   - 迭代次数\n",
    "   - 最小平方误差MSE\n",
    "   - 簇中心点变化率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means 存在问题\n",
    "1. 在迭代过程中使用所有的样本的均值，作为新的质点，如果簇中存在异常点会导致均值偏差比较严重；在当前情况下使用中位数，可能会更好，使用中位数的聚类方式叫做k-medids\n",
    "2. k-means 算法初值敏感， 选择不同的初始值可能导致不同的簇的划分规则\n",
    "    - 可采用多套初始化分规则构造不同的分类规则，选择最优的构造规则。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means优缺点\n",
    "1. 缺点：\n",
    "     - k值是用户给定的，在数据处理前k 是未知的，不同的k值得到的结果也不一样\n",
    "     - 对初始簇中心点敏感\n",
    "     - 不适合非凸形状的簇或者大小差别较大的簇\n",
    "     - 特殊值对模型影响较大\n",
    "2. 优点：\n",
    "    - 理解容易，距离效果不错\n",
    "    - 处理大数据集时，该算法可以保证较好的伸缩性和延展性\n",
    "    - 当簇近似高斯分布的时候，效果非常不错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一、二分K-means算法\n",
    "1. 解决K-means对初始簇心比较敏感的问题，二分K-means，是弱化初始质心的一种算法：\n",
    "   - 将所有样本数据作为一个簇放在一个队列中\n",
    "   - 从队列中选择一个簇进行k-means算法划分，划分为两个簇，将两个子簇放进队列中\n",
    "   - 循环迭代第二部操作，直到终止条件（簇数量，最小平方误差，迭代次数等）\n",
    "   - 队列中的簇就是最终的分类簇集合\n",
    "2. 从队列中选择簇的两种方式：\n",
    "   - 对所有簇计算误差和SSE，选择SSE最大的簇进行划分\n",
    "   - 选择样本数量最多的簇进行划分（簇与簇间数量差距较小）\n",
    "---\n",
    "#### 二、K-means++算法\n",
    "\n",
    "\n",
    "---\n",
    "#### 三、K-means||算法\n",
    "1. K-means++ 的优化算法：改变每次遍历的时候的取样规则，并非每次遍历只获取一个样本，而是每次获取K个样本，重复该取样操作n次，然后再将抽样出来的样本聚类为K个点，最后使用这K个点最为k-means算法的簇心。一般5次重复就可以达到一个较好的效果。\n",
    "---\n",
    "#### canopy 算法，未实现\n",
    "1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mini batch k_means算法（数据规模较大时）\n",
    "1. 采用小规模的数据子集（每次随机抽取数据子集），减少计算时间，同时试图优化目标函数，该算法可减少标准k-means算法的收敛时间，产生结果的效果略差于标准K-means算法\n",
    "2. 算法步骤：\n",
    "    - 抽取部分数据集，使用K-means构建K个聚簇点，\n",
    "    - 继续抽取训练集中的样本数据，并添加到模型中，分配给距离最近的簇心，\n",
    "    - 更新聚簇中心点\n",
    "    - 循环迭代2、3步，直到聚簇中心稳定或达到迭代次数\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 聚类算法衡量指标，前4个需要引入y值\n",
    "1. 混淆矩阵\n",
    "2. 均一性\n",
    "    - 一个簇只包含一个类别的样本，每个聚簇正确分类的样本数占该聚簇样本的总数的比例的和\n",
    "3. 完整性\n",
    "    - 同类样本被归到相同簇中则满足完整性，每个簇正确分类的样本数占该类型的总样本数的比例和\n",
    "4. V-measure\n",
    "    - 均一性和完整性的加权平均\n",
    "5. 调整兰德系数（ARI）\n",
    "6. 调整互信息（AMI）\n",
    "7. 轮廓系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层次聚类方法\n",
    "    对给定的数据集进行层次分解直到满足条件未知，传统的层次聚类算法分为两大类：\n",
    "1. 凝聚的层次聚类：AGNES算法，采用自底向上的策略，最初将每个样本视为一个簇，然后这些簇根据某些准则一步步合并，两个簇间的距离由这两个簇中距离最近的数据点的相似度来确定，合并过程反复进行直到所有对象满足簇的数目\n",
    "2. 分裂的层次聚类：DIANA算法，采用自顶向下的策略，首先将所有对象置于一个簇中，然后按照某种既定规则，细分为越来越小的簇，直到达到某个终止条件\n",
    "\n",
    "#### 优缺点：\n",
    "1. 简单易理解\n",
    "2. 合并点、分裂点选择不容易\n",
    "3. 合并、分裂的操作不易撤销\n",
    "4. 大数据集不适合\n",
    "5. 执行效率低\n",
    "\n",
    "#### AGNES算法簇间距离\n",
    "1. 最小距离\n",
    "    - 两个簇中最近的两个样本的距离\n",
    "2. 最大距离\n",
    "    - 两个簇中最远的两个样本的距离\n",
    "3. 平均距离\n",
    "    - 两个簇中样本间两两距离的平均值\n",
    "    \n",
    "#### 层次聚类的优化方式\n",
    "1. BIRCH算法（平衡迭代削聚类法）\n",
    "    - 适合大规模数据集，线性效率\n",
    "2. CURE算法\n",
    "    - 能够处理非球形分布的场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### 密度聚类算法\n",
    "1. 指导思想：只要样本点的密度大于某个阈值，则将该样本添加到最近的簇中。\n",
    "2. 这类算法可以克服基于距离的算法只能发现凸聚类的缺点，可以发现任意形状的聚类，对噪声数据不敏感\n",
    "3. 计算复杂度高，计算量大\n",
    "4. 常用算法：\n",
    "    - DBSCAN\n",
    "    - 密度最大值算法\n",
    "\n",
    "#### DBSCAN算法\n",
    "1. 将簇定义为**密度相连的点的最大集合**，能够将最狗高密度的区域划分为簇，并在在具有噪声的空间数据中发现任意形状的簇。\n",
    "2. 核心思想：用一个点的ε领域内的邻居点数衡量该点所在空间的密度，该算法可以找到不规则的形状的簇，而且不需要事先给定簇的数量\n",
    "\n",
    "#### 相关概念\n",
    "1. ε领域：给定对象在半径ε内的区域\n",
    "2. 密度：ε领域内样本的密度，是一个数值，依赖于半径\n",
    "3. 阈值：当密度大于某个阈值时，\n",
    "4. 核心点：某个样本密度大于阈值则称为样本的核心点，\n",
    "5. 边界点： 非核心点的ε领域中存在核心点，则称为边界点\n",
    "6. 噪音点：集合中除边界点和核心点之外的点都是噪音点\n",
    "\n",
    "\n",
    "#### 最大密度值聚类算法（MDCA）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 谱聚类\n",
    "#### 基本概念\n",
    "1. 基于谱图理论基础上的一种聚类算法，与传统聚类算法相比，具有在任意样本空间上聚类并且收敛于全局最优解的优点，\n",
    "2. 通过对样本数据的**拉普拉斯矩阵**的特征向量进行聚类，从而达到对样本数据进行聚类的目的，其本质是将聚类问题转换为图的最优划分的问题，是一种点对聚类的算法\n",
    "3. 谱聚类算法是将数据集中的每个对象看作图的顶点V，将顶点间的相似度量化为相应顶点连接边E的权值w,这样就构成了一个基于相似的**无向加权图G(V, E)**，于是聚类问题就转化为图的划分问题，基于图的最优划分规则是：**子图内相似度最大，子图间的相似度最小**\n",
    "\n",
    "#### 实现步骤\n",
    "1. 构建表示对象相似度的矩阵 W\n",
    "2. 构建度矩阵D（对角矩阵）\n",
    "3. 构建拉普拉斯矩阵 L\n",
    "4. 计算矩阵 L 的前 K 个值的特征向量（K 个列向量）\n",
    "5. 将 K 个列向量组成矩阵 U\n",
    "6. 对矩阵 U中的 n 行数据利用K-means或其他经典聚类算法进行聚类得出最终结果\n",
    "\n",
    "#### 拉普拉斯矩阵变形\n",
    "1. 拉普拉斯矩阵：L = D - W\n",
    "2. 对称拉普拉斯矩阵\n",
    "3. 随机游走拉普拉斯矩阵\n",
    "\n",
    "#### 应用场景\n",
    "图形聚类、计算机视觉、非凸球形数据聚类\n",
    "\n",
    "#### 问题\n",
    "1. 相似度矩阵构建的问题：\n",
    "2. 聚类数目的给定\n",
    "3. 如何选择特征向量\n",
    "4. 如何提高谱聚类的效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "cn",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "cn",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
