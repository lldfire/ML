{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义：使用特定的技巧和知识处理数据，使数据在算法上发挥更好的作用\n",
    "    工具：sklearn\n",
    "    特征抽取/提取：\n",
    "    将任意数据类型（文本或图片）转化为可用于机器学习的数字特征\n",
    "    字典特征提取\n",
    "    文本特征提取\n",
    "    图片特征提取\n",
    "    \n",
    "    使用sklearn中的方法可以作到特征提取 sklearn.feature_extraction\n",
    "    字典特征提取：\n",
    "    sklearn.feature_extraction.DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入特征提取的方法\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建字典类型的数据\n",
    "data = [\n",
    "    {'city': '北京', 'temperature': 100, 'salary': 6000},\n",
    "    {'city': '上海', 'temperature': 80, 'salary': 5000},\n",
    "    {'city': '深证', 'temperature': 64, 'salary': 8000},\n",
    "    {'city': '杭州', 'temperature': 40, 'salary': 7000},\n",
    "    {'city': '北京', 'temperature': 10, 'salary': 4000},\n",
    "    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 4)\t6000.0\n",
      "  (0, 5)\t100.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 4)\t5000.0\n",
      "  (1, 5)\t80.0\n",
      "  (2, 3)\t1.0\n",
      "  (2, 4)\t8000.0\n",
      "  (2, 5)\t64.0\n",
      "  (3, 2)\t1.0\n",
      "  (3, 4)\t7000.0\n",
      "  (3, 5)\t40.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 4)\t4000.0\n",
      "  (4, 5)\t10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 6.0e+03, 1.0e+02],\n",
       "       [1.0e+00, 0.0e+00, 0.0e+00, 0.0e+00, 5.0e+03, 8.0e+01],\n",
       "       [0.0e+00, 0.0e+00, 0.0e+00, 1.0e+00, 8.0e+03, 6.4e+01],\n",
       "       [0.0e+00, 0.0e+00, 1.0e+00, 0.0e+00, 7.0e+03, 4.0e+01],\n",
       "       [0.0e+00, 1.0e+00, 0.0e+00, 0.0e+00, 4.0e+03, 1.0e+01]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化转换器类，转化器中有参数sparse 默认为True\n",
    "transfer = DictVectorizer()  # sparse=False\n",
    "# 调用转换器中的方法：fit_transform() 返回一个sparse矩阵(稀疏矩阵，使用数组坐标表示特征值类型)\n",
    "new_data = transfer.fit_transform(data)\n",
    "print(new_data)\n",
    "\n",
    "# 查看特征名\n",
    "transfer.get_feature_names()\n",
    "\n",
    "# 使用 toarray 将数据转化为二维数组\n",
    "new_data.toarray()\n",
    "\n",
    "# 稀疏数组结果如下，\n",
    "# 括号中数字 表示其在二维数组中的位置， 后面那个数据为特征值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "sparse = Ture时的结果展示，以数组的坐标表示特征的类型，\n",
    "    (0, 1)\t1.0\n",
    "    (0, 4)\t100.0\n",
    "    (1, 0)\t1.0\n",
    "    (1, 4)\t80.0\n",
    "    (2, 3)\t1.0\n",
    "    (2, 4)\t64.0\n",
    "    (3, 2)\t1.0\n",
    "    (3, 4)\t40.0\n",
    "\n",
    "sparse = False时的结果展示，\n",
    "     [[  0.   1.   0.   0. 100.]\n",
    "     [  1.   0.   0.   0.  80.]\n",
    "     [  0.   0.   0.   1.  64.]\n",
    "     [  0.   0.   1.   0.  40.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本类数据特征提取\n",
    "    使用单词作为特征\n",
    "    方法1：\n",
    "    CountVectorizer()\n",
    "    实例化转化器对象 --> 调用fit_transform()方法 同字典数据的特征提取\n",
    "    \n",
    "    使用stop_words可以不统计其中部分词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 7)\t2\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 4)\t2\n",
      "  (1, 6)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "['good', 'life', 'like', 'not', 'python', 'tired', 'want', 'work']\n",
      "[[1 0 1 1 0 0 0 2]\n",
      " [0 0 0 0 2 0 1 0]\n",
      " [0 1 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "data2 = ['I do not like work good work', 'i want python python', 'life is so tired python']\n",
    "stop_words = ['is', 'so','do']\n",
    "transfer = CountVectorizer(stop_words=stop_words)\n",
    "new_data2 = transfer.fit_transform(data2)\n",
    "\n",
    "print(new_data2)\n",
    "print(transfer.get_feature_names())\n",
    "print(new_data2.toarray())\n",
    "\n",
    "# 结果如下，括号中前一个数字表示数据集中的索引位置，后一个表示 特征词在特征名列表中的索引， \n",
    "# 单独列出来的数字表示 在文本中出现的词数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  对于中文文本特征提取，可以使用分词库将中文文本进行分词，然后进行特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文分词库  jieba  jieba.cut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键词提取 TF-IDF文本特征提取\n",
    "    使用：TfidfVectorirzer()\n",
    "    思想：如果某个词语或短语在一篇文章中出现的频次很高，但是在其他文章中出现的次数很少，这样的词语适合用来进行分类\n",
    "    作用：衡量一个词在某篇文章中的重要程度\n",
    "    计算：tf * idf\n",
    "        tf:词频 某个单词在谋篇文章中出现的频率 如 一篇文章中有100个词语，某个单词出现了10次，则tf = 0.1\n",
    "        idf:逆向文档词频，使用文件总数除以包含该词汇的文件数目，再将得到的商取以10为底的对数得到\n",
    "            如：有1000篇文章，某个词汇在10篇文章中出现过，则 1000/10 =100  idf = log10 100 = 2\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 案例三\n",
    "data3 = [\n",
    "    '你我虽方外之人，这皮囊却还在欲界，暂处尘世，不得不防人口舌', \n",
    "    '年光似鸟翩翩过，世事如棋局局新。就算你再完美，再努力，也不可能每一次都赢，赢得了一盘，赢得了一天吗？赢得了一天，赢得了一世吗？这世上就没有常胜的将军，凡事尽力就好，不能对结果过于执着。',\n",
    "    '真理不辩不明，没有输赢，佛法在心中，不在言辞之间',\n",
    "    '追求爱情的勇气，守护爱情的决心，维持爱情的智慧',\n",
    "    '恋爱是用来欣赏对方的优点，婚姻是用来忍受对方的缺点。'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你 我 虽 方外之人 ， 这 皮囊 却 还 在 欲界 ， 暂处 尘世 ， 不得不 防 人 口舌', '年光 似鸟 翩翩 过 ， 世事 如 棋局 局新 。 就算 你 再 完美 ， 再 努力 ， 也 不 可能 每 一次 都 赢 ， 赢得 了 一盘 ， 赢得 了 一天 吗 ？ 赢得 了 一天 ， 赢得 了 一世 吗 ？ 这 世上 就 没有 常胜 的 将军 ， 凡事 尽力 就 好 ， 不能 对 结果 过于 执着 。', '真理 不辩 不明 ， 没有 输赢 ， 佛法 在 心中 ， 不 在 言辞 之间', '追求 爱情 的 勇气 ， 守护 爱情 的 决心 ， 维持 爱情 的 智慧', '恋爱 是 用来 欣赏 对方 的 优点 ， 婚姻 是 用来 忍受 对方 的 缺点 。']\n"
     ]
    }
   ],
   "source": [
    "new_data3 = []\n",
    "for da in data3:\n",
    "    new_data3.append(' '.join(list(jieba.cut(da))))\n",
    "    \n",
    "print(new_data3)\n",
    "stop_words = ['你', '我', '这', '在']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一世', '一天', '一次', '一盘', '不得不', '不明', '不能', '不辩', '世上', '世事', '之间', '优点', '似鸟', '佛法', '决心', '凡事', '努力', '勇气', '口舌', '可能', '婚姻', '守护', '完美', '对方', '将军', '尘世', '就算', '尽力', '局新', '常胜', '年光', '心中', '忍受', '恋爱', '执着', '方外之人', '智慧', '暂处', '棋局', '欣赏', '欲界', '没有', '爱情', '用来', '皮囊', '真理', '结果', '维持', '缺点', '翩翩', '言辞', '赢得', '输赢', '过于', '追求']\n",
      "  (0, 35)\t0.3779644730092272\n",
      "  (0, 44)\t0.3779644730092272\n",
      "  (0, 40)\t0.3779644730092272\n",
      "  (0, 37)\t0.3779644730092272\n",
      "  (0, 25)\t0.3779644730092272\n",
      "  (0, 4)\t0.3779644730092272\n",
      "  (0, 18)\t0.3779644730092272\n",
      "  (1, 30)\t0.15312137424538233\n",
      "  (1, 12)\t0.15312137424538233\n",
      "  (1, 49)\t0.15312137424538233\n",
      "  (1, 9)\t0.15312137424538233\n",
      "  (1, 38)\t0.15312137424538233\n",
      "  (1, 28)\t0.15312137424538233\n",
      "  (1, 26)\t0.15312137424538233\n",
      "  (1, 22)\t0.15312137424538233\n",
      "  (1, 16)\t0.15312137424538233\n",
      "  (1, 19)\t0.15312137424538233\n",
      "  (1, 2)\t0.15312137424538233\n",
      "  (1, 51)\t0.6124854969815293\n",
      "  (1, 3)\t0.15312137424538233\n",
      "  (1, 1)\t0.30624274849076466\n",
      "  (1, 0)\t0.15312137424538233\n",
      "  (1, 8)\t0.15312137424538233\n",
      "  (1, 41)\t0.12353736061060211\n",
      "  (1, 29)\t0.15312137424538233\n",
      "  :\t:\n",
      "  (1, 34)\t0.15312137424538233\n",
      "  (2, 41)\t0.2743035641495426\n",
      "  (2, 45)\t0.339992197464673\n",
      "  (2, 7)\t0.339992197464673\n",
      "  (2, 5)\t0.339992197464673\n",
      "  (2, 52)\t0.339992197464673\n",
      "  (2, 13)\t0.339992197464673\n",
      "  (2, 31)\t0.339992197464673\n",
      "  (2, 50)\t0.339992197464673\n",
      "  (2, 10)\t0.339992197464673\n",
      "  (3, 54)\t0.2581988897471611\n",
      "  (3, 42)\t0.7745966692414834\n",
      "  (3, 17)\t0.2581988897471611\n",
      "  (3, 21)\t0.2581988897471611\n",
      "  (3, 14)\t0.2581988897471611\n",
      "  (3, 47)\t0.2581988897471611\n",
      "  (3, 36)\t0.2581988897471611\n",
      "  (4, 33)\t0.26726124191242434\n",
      "  (4, 43)\t0.5345224838248487\n",
      "  (4, 39)\t0.26726124191242434\n",
      "  (4, 23)\t0.5345224838248487\n",
      "  (4, 11)\t0.26726124191242434\n",
      "  (4, 20)\t0.26726124191242434\n",
      "  (4, 32)\t0.26726124191242434\n",
      "  (4, 48)\t0.26726124191242434\n"
     ]
    }
   ],
   "source": [
    "transform = TfidfVectorizer(stop_words=stop_words)\n",
    "tt = transform.fit_transform(new_data3)\n",
    "# print(tt.toarray())\n",
    "\n",
    "print(transform.get_feature_names())\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
