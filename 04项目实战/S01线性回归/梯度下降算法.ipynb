{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类：\n",
    "    1.批量梯度下降（BGD）：每次使用全量的训练集样本来更新模型参数\n",
    "    2.随机梯度下降（SGD）：每次从训练集中随机选择一个样本来进行迭代\n",
    "    3.Mini-batch梯度下降算法：次更新从训练集中随机选择b,b<m个样本进行学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一个数据检验函数，验证样本特征和目标值是否一样，\n",
    "# 每个样本的特征值是否一样，目标值是否单一\n",
    "def checkdate(X, Y):\n",
    "    \"\"\"\n",
    "    检查数据是否规范\n",
    "        X: 特征值, list object\n",
    "        Y: 目标值, list object\n",
    "    \"\"\"\n",
    "    if len(X) != len(Y):\n",
    "        raise Exception('数据异常。')\n",
    "    else:\n",
    "        l = len(X[0])\n",
    "        for m in X:\n",
    "            if len(m) != l:\n",
    "                raise Exception('数据异常。')\n",
    "            if len(Y[0]) != 1:     # 保证目标值数量单一\n",
    "                raise Exception('数据异常。') \n",
    "\n",
    "def calcdiffe(x, y, a):\n",
    "    \"\"\"\n",
    "    计算差值，实际结果与预测结果间的差\n",
    "        x: 某个样本的特征值，向量\n",
    "        y: 样本对应得目标值，\n",
    "    \"\"\"\n",
    "    lx = len(x)\n",
    "    la = len(a)\n",
    "    if lx == la:   # 样本的长度和theta的长度一样\n",
    "        result = 0\n",
    "        for i in range(lx):\n",
    "            result += x[i] * a[i]  # θ1*x1 + θ2*x2 + ```\n",
    "        return y - result\n",
    "    elif lx + 1 == la:    # 有常数项\n",
    "        result = 0\n",
    "        for i in range(lx):\n",
    "            result += x[i] * a[i]\n",
    "        result += 1 * a[lx]    \n",
    "        return y - result\n",
    "    else:\n",
    "        raise Exception('参数错误')\n",
    "\n",
    "        \n",
    "def fit(X, Y, alphas, threshold=1e-6, maxIter=200, addConstant=True):\n",
    "    \"\"\"\n",
    "    梯度下降模型\n",
    "        X: 特征值,2D\n",
    "        Y: 目标值,2D\n",
    "        threshold: 阈值,达到该阈值时,停止迭代\n",
    "    return: \n",
    "    \"\"\"\n",
    "    import math\n",
    "    import numpy as np\n",
    "    # 校验 X Y\n",
    "    checkdate(X, Y)\n",
    "    # 构建模型\n",
    "    l = len(alphas)     # 学习率的长度\n",
    "    m = len(Y)          # 目标值的长度\n",
    "    n = len(X[0]) + 1 if addConstant else len(X[0])    # 特征值的长度\n",
    "    B = [True for i in range(l)]     # 空值最优模型\n",
    "    J = [np.nan for i in range(l)]     # loss的函数值\n",
    "    \n",
    "    # 计算迭代后与迭代前的差异值\n",
    "    # 初始化theta值，初始值均为0，样本的长度等于theta的长度, 一个特征值对应一个theta, \n",
    "    # a 求解的系数，二维数组，m*n  m是样本中的特征值的长度， n是本次测试的学习率的长度\n",
    "    a = [[0 for i in range(n)] for j in range(l)]   \n",
    "    # 开始计算, 最多迭代200次\n",
    "    for times in range(maxIter):\n",
    "        for i in range(l):    # 如果已确定最优解，则退出本次循环\n",
    "            if not B[i]:\n",
    "                continue\n",
    "            \n",
    "            ta = a[i]   # theta的初始值\n",
    "            for j in range(n):       # 样本的特征值\n",
    "                alpha = alphas[i]    # 取出一个学习率\n",
    "                ts = 0\n",
    "                for k in range(m):   # 样本的目标值\n",
    "                    if j == n-1 and addConstant:     # 有常数项\n",
    "                        ts += alpha * calcdiffe(X[k], Y[k][0], a[i]) * 1\n",
    "                    else:\n",
    "                        ts += alpha * calcdiffe(X[k], Y[k][0], a[i]) * X[k][j]\n",
    "                t = ta[j] + ts   # 学习后的theta值\n",
    "                ta[j] = t      #\n",
    "                \n",
    "            flag = True\n",
    "            js = 0\n",
    "            for k in range(m):\n",
    "                js += math.pow(calcdiffe(X[k], Y[k][0], a[i]), 2) + a[i][j]  # 梯度下降求解公式\n",
    "                # 求每个样本的差值的平方 + theta的累加值值\n",
    "                if js > J[i]:\n",
    "                    flag = False\n",
    "                    break\n",
    "            \n",
    "            if flag:\n",
    "                J[i] = js\n",
    "                for j in range(n):\n",
    "                    a[i][j] = ta[j]    # 更新 theta 的值\n",
    "            else:\n",
    "                B[i] = False\n",
    "                \n",
    "            r = [0 for j in J if j < threshold]   # 求解结果，如果小于阈值，则退出循环\n",
    "            if len(r) > 0:\n",
    "                break\n",
    "            \n",
    "            r = [0 for b in B if not b]\n",
    "            if len(r) > 0:\n",
    "                break\n",
    "                \n",
    "    min_a = a[0]    # 找到最小的系数theta\n",
    "    min_j = J[0]\n",
    "    min_alpha = alphas[0]\n",
    "    for i in range(l):\n",
    "        if J[i] < min_j:\n",
    "            min_j = J[i]\n",
    "            min_a = a[i]\n",
    "            min_alpha = alphas[i]\n",
    "            \n",
    "    print('最优的alpha值是：', min_alpha)\n",
    "    return min_a\n",
    "\n",
    "def predict(X, a):\n",
    "    \"\"\"\n",
    "    预测结果\n",
    "    \"\"\"\n",
    "    Y = []\n",
    "    n = len(a) - 1\n",
    "    for x in X:\n",
    "        result = 0\n",
    "        for i in range(n):\n",
    "            result += x[i] * a[i]   # 求所有样本特征乘以系数的累加和\n",
    "        result += a[n]     # 加上常数项\n",
    "        Y.append(result)\n",
    "    return Y\n",
    "\n",
    "\n",
    "# 计算实际值和预测值之间的相关性\n",
    "def calcRScore(y, py):\n",
    "    if len(y) != len(py):\n",
    "        raise Exception(\"参数异常\")\n",
    "    import math \n",
    "    import numpy as np\n",
    "    avgy = np.average(y)\n",
    "    m = len(y)\n",
    "    rss = 0.0\n",
    "    tss = 0\n",
    "    for i in range(m):\n",
    "        rss += math.pow(y[i] - py[i], 2)\n",
    "        tss += math.pow(y[i] - avgy, 2)\n",
    "    r = 1.0 - 1.0 * rss / tss\n",
    "    return r        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression,Ridge, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.linear_model.coordinate_descent import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置字符集，防止中文乱码\n",
    "mpl.rcParams['font.sans-serif']=[u'simHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-18.55967185],\n",
       "       [-17.1576482 ],\n",
       "       [-11.01504472],\n",
       "       [ 89.02611774],\n",
       "       [118.31991291],\n",
       "       [-10.55888129],\n",
       "       [168.02519061],\n",
       "       [115.67331998],\n",
       "       [204.96267299],\n",
       "       [417.70060165]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "np.set_printoptions(linewidth=1000, suppress=True)\n",
    "N = 10\n",
    "x = np.linspace(0, 6, N) + np.random.randn(N)\n",
    "y = 1.8*x**3 + x**2 - 14*x - 7 + np.random.randn(N)\n",
    "x.shape = -1, 1\n",
    "y.shape = -1, 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8374376988248429\n",
      "模块自带实现===============\n",
      "参数列表: [[72.0576022]]\n",
      "截距: [-163.71132966]\n",
      "最优的alpha值是： 0.01\n",
      "自定义实现模型=============\n",
      "参数列表: [70.87936393633888, -158.4997458365991]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6), facecolor='w')\n",
    "\n",
    "## 模拟数据产生\n",
    "x_hat = np.linspace(x.min(), x.max(), num=100)\n",
    "x_hat.shape = -1,1\n",
    "\n",
    "## 线性模型\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "y_hat = model.predict(x_hat)\n",
    "s1 = calcRScore(y, model.predict(x))\n",
    "print(model.score(x,y)) ## 自带R^2输出\n",
    "print(\"模块自带实现===============\")\n",
    "print(\"参数列表:\", model.coef_)\n",
    "print(\"截距:\", model.intercept_)\n",
    "\n",
    "\n",
    "## 自模型\n",
    "ma = fit(x,y,np.logspace(-4,-2,100))\n",
    "y_hat2 = predict(x_hat, ma)\n",
    "s2 = calcRScore(y, predict(x,ma))\n",
    "print (\"自定义实现模型=============\")\n",
    "print (\"参数列表:\", ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
